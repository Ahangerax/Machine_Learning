{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac8ee46",
   "metadata": {},
   "source": [
    "# üìò Machine Learning Mathematics Notebook\n",
    "\n",
    "**Author:** Asif Ahanger  \n",
    "**Purpose:** Core Mathematics for Machine Learning\n",
    "\n",
    "This notebook covers essential mathematical concepts required for Machine Learning with **definitions, explanations, and Python examples**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2e936",
   "metadata": {},
   "source": [
    "## üî¢ 1. Equations\n",
    "\n",
    "An **equation** is a mathematical statement that shows the equality of two expressions.\n",
    "\n",
    "In ML, equations are used to:\n",
    "- Define models\n",
    "- Express loss functions\n",
    "- Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e673b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear equation: ax + b = 0\n",
    "a = 2\n",
    "b = -4\n",
    "\n",
    "x = -b / a\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f9a98",
   "metadata": {},
   "source": [
    "## üìê 2. Linear Algebra\n",
    "\n",
    "Linear Algebra is the **backbone of ML**.\n",
    "\n",
    "It deals with:\n",
    "- Vectors\n",
    "- Matrices\n",
    "- Matrix operations\n",
    "\n",
    "Used heavily in **neural networks, regression, PCA, embeddings**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66999454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vectors\n",
    "asif = np.array([1, 2, 3])\n",
    "ahanger = np.array([4, 5, 6])\n",
    "\n",
    "dot_product = np.dot(asif, ahanger)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc34e0",
   "metadata": {},
   "source": [
    "### üî≤ Matrix Multiplication\n",
    "\n",
    "Matrix multiplication is used in **forward propagation** of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5552c322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26, 36],\n",
       "       [46, 64]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_mat = np.array([[2, 3], [4, 5]])\n",
    "B_mat = np.array([[4, 6], [6, 8]])\n",
    "\n",
    "A_mat @ B_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac8db6",
   "metadata": {},
   "source": [
    "### üîÅ Transpose of Matrix\n",
    "\n",
    "Transpose flips rows into columns.\n",
    "\n",
    "Used in **gradient calculations and optimization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479b3483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Danish = np.array([[1, 2], [3, 4]])\n",
    "Danish.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29d873",
   "metadata": {},
   "source": [
    "## üìâ 3. Differential Calculus\n",
    "\n",
    "Differential calculus deals with **rates of change**.\n",
    "\n",
    "In ML it is used for:\n",
    "- Gradient Descent\n",
    "- Loss minimization\n",
    "- Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9feaad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Descent Example\n",
    "\n",
    "w = 5          # initial weight\n",
    "lr = 0.1       # learning rate\n",
    "\n",
    "# derivative of loss = w^2 is 2w\n",
    "gradient = 2 * w\n",
    "w = w - lr * gradient\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c6a1b",
   "metadata": {},
   "source": [
    "## üìä 4. Probability\n",
    "\n",
    "Probability measures the **likelihood of events**.\n",
    "\n",
    "Used in ML for:\n",
    "- Classification\n",
    "- Uncertainty modeling\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d70ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(25.0), np.float64(125.0), np.float64(11.180339887498949))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean, Variance, Standard Deviation\n",
    "\n",
    "Tawqeer = np.array([10, 20, 30, 40])\n",
    "\n",
    "mean = np.mean(Tawqeer)\n",
    "variance = np.var(Tawqeer)\n",
    "std_dev = np.std(Tawqeer)\n",
    "\n",
    "mean, variance, std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6996c0",
   "metadata": {},
   "source": [
    "### üé≤ Random Variables & Normal Distribution\n",
    "\n",
    "Many ML algorithms assume data follows a **normal distribution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b5d430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21422157,  1.54292053,  1.64483243, -1.13610975, -0.88939877,\n",
       "        0.42912518,  0.01466276,  2.0462194 ,  0.71457549,  0.17234994])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = np.random.normal(loc=0, scale=1, size=100)\n",
    "samples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98797fb6",
   "metadata": {},
   "source": [
    "## üìê 5. Bayes Theorem\n",
    "\n",
    "**Bayes Theorem** helps update probability using new evidence.\n",
    "\n",
    "Formula:\n",
    "\n",
    "P(A|B) = (P(B|A) √ó P(A)) / P(B)\n",
    "\n",
    "Used in **Naive Bayes classifiers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c913f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_A = 0.3\n",
    "P_B_given_A = 0.8\n",
    "P_B = 0.5\n",
    "\n",
    "P_A_given_B = (P_B_given_A * P_A) / P_B\n",
    "P_A_given_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08aed2",
   "metadata": {},
   "source": [
    "## üìà 6. Correlation\n",
    "\n",
    "Correlation measures the **relationship between variables**.\n",
    "\n",
    "Important for **feature selection**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fe5987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array([10, 20, 30, 40])\n",
    "\n",
    "np.corrcoef(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c05115a",
   "metadata": {},
   "source": [
    "## üìâ 7. Loss Function (MSE)\n",
    "\n",
    "Loss functions measure **how wrong a model is**.\n",
    "\n",
    "Mean Squared Error (MSE) is widely used in regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6ffaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6666666666666666)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([3, 5, 7])\n",
    "y_pred = np.array([2, 5, 8])\n",
    "\n",
    "loss = np.mean((y_true - y_pred) ** 2)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".machine (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
